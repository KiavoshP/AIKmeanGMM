{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from helper_functions import image_to_matrix, matrix_to_image, \\\n",
    "    flatten_image_matrix\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "from helper_functions import image_difference, default_convergence\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_means_test(unittest.TestCase):\n",
    "    def runTest(self):\n",
    "        pass\n",
    "\n",
    "    def test_initial_means(self, initial_means):\n",
    "        image_file = 'images/Starry.png'\n",
    "        image_values = image_to_matrix(image_file).reshape(-1, 3)\n",
    "        m, n = image_values.shape\n",
    "        for k in range(1, 10):\n",
    "            means = initial_means(image_values, k)\n",
    "            self.assertEqual(means.shape, (k, n),\n",
    "                             msg=(\"Initialization for %d dimensional array \"\n",
    "                                  \"with %d clusters returned an matrix of an incompatible dimension.\") % (n, k))\n",
    "            for mean in means:\n",
    "                self.assertTrue(any(np.equal(image_values, mean).all(1)), \n",
    "                                msg=(\"Means should be points from given array\"))\n",
    "\n",
    "    def test_k_means_step(self, k_means_step):\n",
    "        initial_means = [\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237], [0, 0, 0]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237], [0, 0, 0],\n",
    "                      [0.8392157, 0.80392158, 0.63921571]]),\n",
    "        ]\n",
    "\n",
    "        expected_new_means = [\n",
    "            np.array([[0.80551694, 0.69010299, 0.17438512],\n",
    "                      [0.33569541, 0.45309059, 0.52275014]]),\n",
    "            np.array([[0.82325169, 0.83027274, 0.49915016],\n",
    "                      [0.5706171,  0.70232249, 0.72329472],\n",
    "                      [0.25756221, 0.35204852, 0.40436148]]),\n",
    "            np.array([[0.81913559, 0.82433047, 0.48307031],\n",
    "                      [0.56450876, 0.69757995, 0.71964568],\n",
    "                      [0.25756221, 0.35204852, 0.40436148],\n",
    "                      [0.80715786, 0.88434938, 0.8546841 ]]),\n",
    "            np.array([[0.81913559, 0.82433047, 0.48307031],\n",
    "                      [0.56450876, 0.69757995, 0.71964568],\n",
    "                      [0.37062106, 0.48453161, 0.5107251 ],\n",
    "                      [0.80715786, 0.88434938, 0.8546841 ],\n",
    "                      [0.09686573, 0.16374335, 0.25318128]]),\n",
    "            np.array([[0.89840523, 0.87403922, 0.52888891],\n",
    "                      [0.5291115,  0.68206999, 0.76917248],\n",
    "                      [0.36574703, 0.480494,   0.51145273],\n",
    "                      [0.80699967, 0.8843717,  0.85660891],\n",
    "                      [0.09686573, 0.16374335, 0.25318128],\n",
    "                      [0.68161022, 0.74824015, 0.55152448]])\n",
    "        ]\n",
    "\n",
    "        expected_cluster_sums = [111069, 195753, 197783, 263443, 303357]\n",
    "\n",
    "        k_min = 2\n",
    "        k_max = 6\n",
    "        image_file = 'images/Starry.png'\n",
    "        image_values = image_to_matrix(image_file).reshape(-1, 3)\n",
    "        m, n = image_values.shape\n",
    "        for i, k in enumerate(range(k_min, k_max + 1)):\n",
    "            new_means, new_clusters = k_means_step(image_values, k=k, means=initial_means[k - k_min])\n",
    "            self.assertTrue(new_means.shape == initial_means[k - k_min].shape,\n",
    "                            msg=\"New means array are of an incorrect shape. Expected: %s got: %s\" %\n",
    "                                (initial_means[k - k_min].shape, new_means.shape))\n",
    "            self.assertTrue(new_clusters.shape[0] == m,\n",
    "                            msg=\"New clusters array are of an incorrect shape. Expected: %s got: %s\" %\n",
    "                                (m, new_clusters.shape))\n",
    "            self.assertTrue(np.allclose(new_means, expected_new_means[i], atol = 1e-4),\n",
    "                            msg=\"Incorrect new mean values.\")\n",
    "            self.assertTrue(np.sum(new_clusters) == expected_cluster_sums[i],\n",
    "                            msg=\"Incorrect clusters prediction.\")\n",
    "        print_success_message()\n",
    "\n",
    "    def test_k_means(self, k_means_cluster):\n",
    "        \"\"\"\n",
    "        Testing your implementation\n",
    "        of k-means on the segmented\n",
    "        Starry reference images.\n",
    "        \"\"\"\n",
    "        k_min = 2\n",
    "        k_max = 6\n",
    "        image_dir = 'images/'\n",
    "        image_name = 'Starry.png'\n",
    "        image_values = image_to_matrix(image_dir + image_name)\n",
    "        # initial mean for each k value\n",
    "        initial_means = [\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237], [0, 0, 0]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237], [0, 0, 0],\n",
    "                      [0.8392157, 0.80392158, 0.63921571]]),\n",
    "        ]\n",
    "        # test different k values to find best\n",
    "        for k in range(k_min, k_max + 1):\n",
    "            updated_values = k_means_cluster(image_values, k,\n",
    "                                             initial_means[k - k_min])\n",
    "            ref_image = image_dir + 'k%d_%s' % (k, image_name)\n",
    "            ref_values = image_to_matrix(ref_image)\n",
    "            dist = image_difference(updated_values, ref_values)\n",
    "            self.assertEqual(int(dist), 0, msg=(\"Clustering for %d clusters\"\n",
    "                                                + \"produced unrealistic image segmentation.\") % k)\n",
    "        print_success_message()\n",
    "\n",
    "def get_initial_means(array, k):\n",
    "    \"\"\"\n",
    "    Picks k random points from the 2D array \n",
    "    (without replacement) to use as initial \n",
    "    cluster means\n",
    "\n",
    "    params:\n",
    "    array = numpy.ndarray[numpy.ndarray[float]] - m x n | datapoints x features\n",
    "\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    initial_means = numpy.ndarray[numpy.ndarray[float]]\n",
    "    \"\"\"\n",
    "    targets = [int(np.random.rand() * 10) for i in range(k)]\n",
    "    return(array[targets])\n",
    "\n",
    "def k_means_step(X, k, means):\n",
    "    \"\"\"\n",
    "    A single update/step of the K-means algorithm\n",
    "    Based on a input X and current mean estimate,\n",
    "    predict clusters for each of the pixels and \n",
    "    calculate new means. \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n | pixels x features (already flattened)\n",
    "    k = int\n",
    "    means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "\n",
    "    returns:\n",
    "    (new_means, clusters)\n",
    "    new_means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    clusters = numpy.ndarray[int] - m sized vector\n",
    "    \"\"\"\n",
    "    \n",
    "    clusters = np.array(\n",
    "        [\n",
    "        sorted([(c,np.linalg.norm((j-means[c]), 2)) \n",
    "                for c in range(k)],\n",
    "                  key = lambda x: x[1])[0][0] \n",
    "        for j in X])\n",
    "    # clusters = np.array(\n",
    "    #     [\n",
    "    #     sorted([(c,np.sqrt(np.power(np.sum(j-means[c]), 2)))\n",
    "    #             for c in range(k)],\n",
    "    #               key = lambda x: x[1])[0][0] \n",
    "    #     for j in X])\n",
    "    \n",
    "    new_means = np.array([np.mean(X[clusters == i, :], 0) for i in set(clusters)])\n",
    "    return(new_means, clusters)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_initial_means(array, k):\n",
    "    \"\"\"\n",
    "    Picks k random points from the 2D array \n",
    "    (without replacement) to use as initial \n",
    "    cluster means\n",
    "\n",
    "    params:\n",
    "    array = numpy.ndarray[numpy.ndarray[float]] - m x n | datapoints x features\n",
    "\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    initial_means = numpy.ndarray[numpy.ndarray[float]]\n",
    "    \"\"\"\n",
    "    # targets = [int(np.random.rand() * 10) for i in range(k)]\n",
    "    # return(array[targets])\n",
    "    N = array.shape[0]\n",
    "    indx = np.random.choice(N,size = k, replace = False)\n",
    "\n",
    "    return(array[indx,:])\n",
    "\n",
    "\n",
    "def k_means_step(X, k, means):\n",
    "    \"\"\"\n",
    "    A single update/step of the K-means algorithm\n",
    "    Based on a input X and current mean estimate,\n",
    "    predict clusters for each of the pixels and \n",
    "    calculate new means. \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n | pixels x features (already flattened)\n",
    "    k = int\n",
    "    means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "\n",
    "    returns:\n",
    "    (new_means, clusters)\n",
    "    new_means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    clusters = numpy.ndarray[int] - m sized vector\n",
    "    \"\"\"\n",
    "    \n",
    "    distance = compute_distance(X, means, k)\n",
    "    y = np.argmin(distance, axis=1)\n",
    "    \n",
    "    new_mean = np.zeros((k, X.shape[1]))\n",
    "    for k_ in range(k):\n",
    "        new_mean[k_, :] = np.mean(X[y == k_, :], axis=0)\n",
    "    \n",
    "    return(new_mean, y)\n",
    "\n",
    "def compute_distance(X, centroids, k):\n",
    "        distance = np.zeros((X.shape[0], k))\n",
    "        for k in range(k):\n",
    "            row_norm = np.linalg.norm(X - centroids[k, :], axis=1)\n",
    "            distance[:, k] = np.square(row_norm)\n",
    "        return distance\n",
    "\n",
    "\n",
    "def k_means_segment(image_values, k=3, initial_means=None):\n",
    "\n",
    "    not_converged = True\n",
    "    steps = 0\n",
    "    max_ittr = 250\n",
    "    X = image_values.reshape((-1,3))\n",
    "    old_mean = get_initial_means(X, k=k)\n",
    "\n",
    "    while not_converged and steps < max_ittr: \n",
    "        new_mean, y = k_means_step(X, k, old_mean)\n",
    "\n",
    "        if np.all(new_mean == old_mean):\n",
    "            not_converged = False\n",
    "        old_mean = new_mean\n",
    "        steps += 1\n",
    "\n",
    "    im_val = X\n",
    "    for i in range(k):\n",
    "        im_val[y == i] = old_mean[i] \n",
    "    \n",
    "    return im_val.reshape(image_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = get_initial_means(X, k=k)\n",
    "X = \n",
    "\n",
    "distance = np.zeros((X.shape[0], 5))\n",
    "for k in range(k):\n",
    "    row_norm = np.linalg.norm(X - centroids[k, :], axis=1)\n",
    "    distance[:, k] = np.square(row_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "k_min = 2\n",
    "k_max = 6\n",
    "image_dir = 'images/'\n",
    "image_name = 'Starry.png'\n",
    "image_values = image_to_matrix(image_dir + image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated = k_means_segment(image_values=image_values, k=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = 'images/'\n",
    "image_name = 'Starry.png'\n",
    "ref_image = image_dir + 'k%d_%s' % (k, image_name)\n",
    "ref_values = image_to_matrix(ref_image)\n",
    "dist = image_difference(updated, ref_values)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_dist(x, y):  # [5 pts]\n",
    "    np.random.seed(1)\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: N x D numpy array\n",
    "        y: M x D numpy array\n",
    "    Return:\n",
    "        dist: N x M array, where dist2[i, j] is the euclidean distance between\n",
    "        x[i, :] and y[j, :]\n",
    "    \"\"\"\n",
    "    x = np.asarray(x[:,np.newaxis,:])\n",
    "    y = np.asarray(y[np.newaxis,:,:])\n",
    "    dist = np.sum(np.abs(y-x)**2, axis=-1)**(1./2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MU' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1636\\2948968511.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# y = np.argmin(distance, axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# X[y == k]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpairwise_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MU' is not defined"
     ]
    }
   ],
   "source": [
    "# distance = compute_distance(X, MU, k)\n",
    "# pairwise_dist(X, )\n",
    "# y = np.argmin(distance, axis=1)\n",
    "# X[y == k]\n",
    "idx = np.array([np.argmin(i) for i in pairwise_dist(X, MU)])\n",
    "\n",
    "\n",
    "sigma = np.array([np.cov(X[idx == k].T) for k in range(MU.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = covariance\n",
    "mu = mean\n",
    "x = X[:5]\n",
    "body = np.zeros((mu.shape[0], x.shape[0], x.shape[1]))\n",
    "for k in range(mu.shape[0]):\n",
    "    body[k] = np.array([x[m] - mu[k] for m in range(x.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = covariance\n",
    "mu = mean\n",
    "X = image_values.reshape((-1,3))\n",
    "x = X[:5]\n",
    "body = x - mu\n",
    "TTTT = np.einsum('ij,ji->i', np.dot(body, np.linalg.pinv(sigma)) , body.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8056402030255776"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponent = (-1/2)*TTTT\n",
    "\n",
    "1/ (np.sqrt((2*np.pi)**x.shape[0] *(np.linalg.det(sigma))))\n",
    "\n",
    "dinom = 1/(np.sqrt((2*np.pi)**x.shape[0] *(np.linalg.det(sigma))))\n",
    "\n",
    "prob = dinom*np.exp(exponent)\n",
    "\n",
    "np.sum(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = 'images/Starry.png'\n",
    "image_matrix = image_to_matrix(image_file)\n",
    "image_matrix = image_matrix.reshape(-1, 3)\n",
    "m, n = image_matrix.shape\n",
    "mean = np.array([0.0627451, 0.10980392, 0.54901963])\n",
    "covariance = np.array([[0.28756526, 0.13084501, -0.09662368],\n",
    "                        [0.13084501, 0.11177602, -0.02345659],\n",
    "                        [-0.09662368, -0.02345659, 0.11303925]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(X, k):\n",
    "    \"\"\"\n",
    "    Return initial values for training of the GMM\n",
    "    Set component mean to a random\n",
    "    pixel's value (without replacement),\n",
    "    based on the mean calculate covariance matrices,\n",
    "    and set each component mixing coefficient (PIs)\n",
    "    to a uniform values\n",
    "    (e.g. 4 components -> [0.25,0.25,0.25,0.25]).\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    (MU, SIGMA, PI)\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k \n",
    "    \"\"\"\n",
    "    MU = get_initial_means(X, k)\n",
    "    SIGMA = compute_sigma(X, MU)\n",
    "    PI = np.array([1/k for t in range(1, k+1)])\n",
    "    return(MU,SIGMA,PI)\n",
    "\n",
    "def compute_sigma(X, MU):\n",
    "    \"\"\"\n",
    "    Calculate covariance matrix, based in given X and MU values\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    \n",
    "    returns:\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    \"\"\"\n",
    "    body = np.zeros((MU.shape[0], X.shape[0], X.shape[1]))\n",
    "    for k in range(MU.shape[0]):\n",
    "        body[k] = np.array([X[m] - MU[k] for m in range(X.shape[0])])\n",
    "    sigma = np.array([np.matmul(body[k].T, body[k]) for k in range(body.shape[0])])/X.shape[0]\n",
    "    return sigma\n",
    "\n",
    "def prob(x, mu, sigma):\n",
    "    \"\"\"Calculate the probability of x (a single\n",
    "    data point or an array of data points) under the\n",
    "    component with the given mean and covariance.\n",
    "    The function is intended to compute multivariate\n",
    "    normal distribution, which is given by N(x;MU,SIGMA).\n",
    "\n",
    "    params:\n",
    "    x = numpy.ndarray[float] (for single datapoint) a\n",
    "        or numpy.ndarray[numpy.ndarray[float]] (for array of datapoints)\n",
    "    mu = numpy.ndarray[float]\n",
    "    sigma = numpy.ndarray[numpy.ndarray[float]]\n",
    "\n",
    "    returns:\n",
    "    probability = float (for single datapoint) \n",
    "                or numpy.ndarray[float] (for array of datapoints)\n",
    "    \"\"\"\n",
    "    probib = None\n",
    "    bridge = x\n",
    "    if len(x.shape) == 1 :\n",
    "        bridge = np.empty((1,len(x)))\n",
    "        bridge = np.array([x])\n",
    "\n",
    "    body = bridge - mu\n",
    "    exponent = -1/2 * np.einsum('ij,ji->i', np.dot(body, np.linalg.pinv(sigma)), body.T)\n",
    "    dinom = 1/(np.sqrt((2*np.pi)**bridge.shape[1] *(np.linalg.det(sigma))))\n",
    "    probib = (dinom)*np.exp(exponent)\n",
    "    if len(x.shape) == 1:\n",
    "        return probib[0]\n",
    "    \n",
    "    return probib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146343.1039485228"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "MU,SIGMA,PI = initialize_parameters(X, k) \n",
    "log_likelihood = 0\n",
    "\n",
    "for i in range(MU.shape[0], X.shape[0], MU.shape[0]):\n",
    "    weighted_sum = 0\n",
    "    for j in range(k):\n",
    "        weighted_sum += PI[j] * prob(X[i], mu=MU[j], sigma=SIGMA[j])\n",
    "    log_likelihood += np.log(weighted_sum)\n",
    "    \n",
    "\n",
    "log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted = np.zeros((k, X.shape[0]))\n",
    "weighted = 0\n",
    "for j in range(k):\n",
    "    weighted += PI[j] *prob(X, mu=MU[j], sigma=SIGMA[j])\n",
    "np.log(np.sum(weighted))\n",
    "\n",
    "# np.log(np.sum(np.sum(weighted, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comp_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_45744\\36746017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmin_bic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmax_likelihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeans\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomp_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvergence_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_convergence\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comp_means' is not defined"
     ]
    }
   ],
   "source": [
    "n_comp_min_bic = None\n",
    "n_comp_max_likelihood = None\n",
    "min_bic = 0\n",
    "max_likelihood = 0\n",
    "for k, means in enumerate(comp_means, start=1):\n",
    "    pi, mu, sigma = train_model(image_matrix, k=k, convergence_function=default_convergence ,means=means)\n",
    "\n",
    "    bic = bayes_info_criterion(image_matrix, pi, mu, sigma, k)\n",
    "\n",
    "    if bic < min_bic:\n",
    "        min_bic = bic\n",
    "        n_comp_min_bic = k\n",
    "    likelihood = loglikelihood(image_matrix, pi, mu, sigma, mu.shape[0])\n",
    "    if likelihood > max_likelihood:\n",
    "        max_likelihood = likelihood\n",
    "        n_comp_max_likelihood = k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def k_means_segment(image_values, k=3, initial_means=None):\n",
    "    not_converged = True\n",
    "    steps = 0\n",
    "    max_ittr = 20000\n",
    "    X = image_values.reshape((-1,3))\n",
    "    old_mean = get_initial_means(X, k=k)\n",
    "    while not_converged and steps < max_ittr: \n",
    "        \n",
    "        clusters = [[] for i in range(k)]\n",
    "        for dp_indx, dp in enumerate(X):\n",
    "            distance = [dist(dp, old_mean[c]) for c in range(k)]\n",
    "            clusters[np.argmin(distance)].append(dp_indx)\n",
    "                \n",
    "        new_mean = np.zeros((k, X.shape[1]))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            cluster_mean = np.mean(X[cluster], axis=0)\n",
    "            new_mean[cluster_idx] = cluster_mean\n",
    "\n",
    "        if dist(new_mean, old_mean) == 0:\n",
    "            not_converged = False\n",
    "\n",
    "        old_mean = new_mean\n",
    "        steps += 1\n",
    "\n",
    "    im_val = X\n",
    "    for i in range(k):\n",
    "        im_val[clusters == i] = old_mean[i] \n",
    "\n",
    "    return im_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_means = [\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237], [0, 0, 0]]),\n",
    "            np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237], [0, 0, 0],\n",
    "                      [0.8392157, 0.80392158, 0.63921571]]),\n",
    "        ]\n",
    "\n",
    "k = 4 \n",
    "# updated_values = k_means_segment(image_values, k, initial_means[k - 2])\n",
    "# ref_image = image_dir + 'k%d_%s' % (k, image_name)\n",
    "# ref_values = image_to_matrix(ref_image)\n",
    "# dist = image_difference(updated_values, ref_values)\n",
    "\n",
    "not_converged = True\n",
    "steps = 0\n",
    "max_ittr = 20000\n",
    "old_mean = None\n",
    "old_mean = get_initial_means()\n",
    "while not_converged and steps < max_ittr: \n",
    "        steps += 1\n",
    "        clusters = [[] for i in range(k)]\n",
    "        for dp_indx, dp in enumerate(image_values):\n",
    "                distance = [dist(dp, old_mean[c]) for c in range(k)]\n",
    "                clusters[np.argmin(distance)].append(dp_indx)\n",
    "                \n",
    "        centroids = np.zeros((k, image_values.shape[1]))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            cluster_mean = np.mean(image_values[cluster], axis=0)\n",
    "            centroids[cluster_idx] = cluster_mean\n",
    "        print(new_mean.shape, old_mean.shape)\n",
    "        # if new_mean.shape[0] != k:\n",
    "        #     old_mean = get_initial_means(image_values, k)\n",
    "        #     print(f'BAD   {old_mean} in Step   {steps}')\n",
    "        #     continue\n",
    "        if steps > 2 and  np.sum(new_mean - old_mean) == 0:\n",
    "                not_converged = False\n",
    "        old_mean = new_mean\n",
    "        print(steps)\n",
    "\n",
    "im_val = image_values\n",
    "for i in range(k):\n",
    "        im_val[clusters == i] = old_mean[i] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_dist(x, y):  # [5 pts]\n",
    "    np.random.seed(1)\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: N x D numpy array\n",
    "        y: M x D numpy array\n",
    "    Return:\n",
    "        dist: N x M array, where dist2[i, j] is the euclidean distance between\n",
    "        x[i, :] and y[j, :]\n",
    "    \"\"\"\n",
    "    x = np.asarray(x[:,np.newaxis,:])\n",
    "    y = np.asarray(y[np.newaxis,:,:])\n",
    "    dist = np.sum(np.abs(y-x)**2, axis=-1)**(1./2)\n",
    "    return dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "%d format: a number is required, not KMeans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39812\\3589065102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'images/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Starry.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mref_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'k%d_%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mref_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_to_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdated_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: %d format: a number is required, not KMeans"
     ]
    }
   ],
   "source": [
    "image_dir = 'images/'\n",
    "image_name = 'Starry.png'\n",
    "ref_image = image_dir + 'k%d_%s' % (k, image_name)\n",
    "ref_values = image_to_matrix(ref_image)\n",
    "dist = image_difference(updated_values, ref_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from helper_functions import *\n",
    "\n",
    "def get_initial_means(array, k):\n",
    "    \"\"\"\n",
    "    Picks k random points from the 2D array\n",
    "    (without replacement) to use as initial\n",
    "    cluster means\n",
    "\n",
    "    params:\n",
    "    array = numpy.ndarray[numpy.ndarray[float]] - m x n | datapoints x features\n",
    "\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    initial_means = numpy.ndarray[numpy.ndarray[float]]\n",
    "    \"\"\"\n",
    "    \n",
    "    N = array.shape[0]\n",
    "    indx = np.random.choice(N,size = k, replace = False)\n",
    "\n",
    "    return(array[indx,:])\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def compute_distance(X, centroids, k):\n",
    "    #Used by ML course HW distance calculation.\n",
    "    distance = np.zeros((X.shape[0], k))\n",
    "    for k in range(k):\n",
    "        row_norm = np.linalg.norm(X - centroids[k, :], axis=1)\n",
    "        distance[:, k] = np.square(row_norm)\n",
    "    return distance\n",
    "\n",
    "def k_means_step(X, k, means):\n",
    "    \"\"\"\n",
    "    A single update/step of the K-means algorithm\n",
    "    Based on a input X and current mean estimate,\n",
    "    predict clusters for each of the pixels and\n",
    "    calculate new means.\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n | pixels x features (already flattened)\n",
    "    k = int\n",
    "    means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "\n",
    "    returns:\n",
    "    (new_means, clusters)\n",
    "    new_means = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    clusters = numpy.ndarray[int] - m sized vector\n",
    "    \"\"\"\n",
    "\n",
    "    distance = compute_distance(X, means, k)\n",
    "    y = np.argmin(distance, axis=1)\n",
    "\n",
    "    new_mean = np.zeros((k, X.shape[1]))\n",
    "    for k_ in range(k):\n",
    "        new_mean[k_, :] = np.mean(X[y == k_, :], axis=0)\n",
    "\n",
    "    return(new_mean, y)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def k_means_segment(image_values, k=3, initial_means=None):\n",
    "    \"\"\"\n",
    "    Separate the provided RGB values into\n",
    "    k separate clusters using the k-means algorithm,\n",
    "    then return an updated version of the image\n",
    "    with the original values replaced with\n",
    "    the corresponding cluster values.\n",
    "\n",
    "    params:\n",
    "    image_values = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - r x c x ch\n",
    "    k = int\n",
    "    initial_means = numpy.ndarray[numpy.ndarray[float]] or None\n",
    "\n",
    "    returns:\n",
    "    updated_image_values = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - r x c x ch\n",
    "    \"\"\"\n",
    "    not_converged = True\n",
    "    steps = 0\n",
    "    max_ittr = 250\n",
    "    X = flatten_image_matrix(image_matrix=image_values)\n",
    "\n",
    "    if (initial_means).any() is None:\n",
    "        old_mean = get_initial_means(X, k=k)\n",
    "    else:\n",
    "        old_mean = initial_means\n",
    "\n",
    "    while not_converged and steps < max_ittr:\n",
    "        new_mean, y = k_means_step(X, k, old_mean)\n",
    "        if np.all(new_mean == old_mean):\n",
    "            not_converged = False\n",
    "        old_mean = new_mean\n",
    "        steps += 1\n",
    "\n",
    "    im_val = X\n",
    "\n",
    "    for i in range(k):\n",
    "        im_val[y == i] = old_mean[i]\n",
    "\n",
    "    return im_val.reshape(image_values.shape)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def compute_sigma(X, MU):\n",
    "    \"\"\"\n",
    "    Calculate covariance matrix, based in given X and MU values\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "\n",
    "    returns:\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    \"\"\"\n",
    "    body = np.zeros((MU.shape[0], X.shape[0], X.shape[1]))\n",
    "    for k in range(MU.shape[0]):\n",
    "        body[k] = np.array([X[m] - MU[k] for m in range(X.shape[0])])\n",
    "    sigma = np.array([np.matmul(body[k].T, body[k]) for k in range(body.shape[0])])/X.shape[0]\n",
    "    return sigma\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def initialize_parameters(X, k):\n",
    "    \"\"\"\n",
    "    Return initial values for training of the GMM\n",
    "    Set component mean to a random\n",
    "    pixel's value (without replacement),\n",
    "    based on the mean calculate covariance matrices,\n",
    "    and set each component mixing coefficient (PIs)\n",
    "    to a uniform values\n",
    "    (e.g. 4 components -> [0.25,0.25,0.25,0.25]).\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    (MU, SIGMA, PI)\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k\n",
    "    \"\"\"\n",
    "    MU = get_initial_means(X, k)\n",
    "    SIGMA = compute_sigma(X, MU)\n",
    "    PI = np.array([1/k for t in range(1, k+1)])\n",
    "    return(MU,SIGMA,PI)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def prob(x, mu, sigma):\n",
    "    \"\"\"Calculate the probability of x (a single\n",
    "    data point or an array of data points) under the\n",
    "    component with the given mean and covariance.\n",
    "    The function is intended to compute multivariate\n",
    "    normal distribution, which is given by N(x;MU,SIGMA).\n",
    "\n",
    "    params:\n",
    "    x = numpy.ndarray[float] (for single datapoint) a\n",
    "        or numpy.ndarray[numpy.ndarray[float]] (for array of datapoints)\n",
    "    mu = numpy.ndarray[float]\n",
    "    sigma = numpy.ndarray[numpy.ndarray[float]]\n",
    "\n",
    "    returns:\n",
    "    probability = float (for single datapoint)\n",
    "                or numpy.ndarray[float] (for array of datapoints)\n",
    "    \"\"\"\n",
    "    probib = None\n",
    "    bridge = x\n",
    "    if len(x.shape) == 1 :\n",
    "        bridge = np.empty((1,len(x)))\n",
    "        bridge = np.array([x])\n",
    "    body = bridge - mu\n",
    "    exponent = -1/2 * np.einsum('ij,ji->i', np.dot(body, np.linalg.pinv(sigma)), body.T)\n",
    "    dinom = 1/(np.sqrt((2*np.pi)**bridge.shape[1] *(np.linalg.det(sigma))))\n",
    "    probib = (dinom)*np.exp(exponent)\n",
    "    if len(x.shape) == 1:\n",
    "        return probib[0]\n",
    "\n",
    "    return probib\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def E_step(X,MU,SIGMA,PI,k):\n",
    "    \"\"\"\n",
    "    E-step - Expectation\n",
    "    Calculate responsibility for each\n",
    "    of the data points, for the given\n",
    "    MU, SIGMA and PI.\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    responsibility = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    responsibility = np.zeros((k, m))\n",
    "    responsibility = np.array([PI[i] * prob(X, mu=MU[i, :], sigma=SIGMA[i, :, :]) for i in range(k)])\n",
    "    responsibility /= np.sum(responsibility, axis=0)\n",
    "    return responsibility\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def M_step(X, r, k):\n",
    "    \"\"\"\n",
    "    M-step - Maximization\n",
    "    Calculate new MU, SIGMA and PI matrices\n",
    "    based on the given responsibilities.\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    (new_MU, new_SIGMA, new_PI)\n",
    "    new_MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    new_SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    new_PI = numpy.ndarray[float] - k\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    new_PI = np.mean(r, axis=1)\n",
    "    new_MU = np.zeros((k, n))\n",
    "    new_MU = np.array([np.sum(r[k].reshape(-1, 1) * X, axis=0) / np.sum(r[k]) for k in range(k)])\n",
    "    new_SIGMA = np.zeros((k, n, n))\n",
    "    for i in range(k):\n",
    "        X_centered = X - new_MU[i]\n",
    "        new_SIGMA[i] = (X_centered.T * r[i]).dot(X_centered) / np.sum(r[i])\n",
    "\n",
    "    return (new_MU, new_SIGMA, new_PI)\n",
    "\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def loglikelihood(X, PI, MU, SIGMA, k):\n",
    "    \"\"\"Calculate a log likelihood of the\n",
    "    trained model based on the following\n",
    "    formula for posterior probability:\n",
    "\n",
    "    log(Pr(X | mixing, mean, stdev)) = sum((i=1 to m), log(sum((j=1 to k),\n",
    "                                      mixing_j * N(x_i | mean_j,stdev_j))))\n",
    "\n",
    "    Make sure you are using natural log, instead of log base 2 or base 10.\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    log_likelihood = float\n",
    "    \"\"\"\n",
    "    weighted = 0\n",
    "    for j in range(k):\n",
    "        weighted += PI[j] *prob(X, mu=MU[j], sigma=SIGMA[j])\n",
    "    return np.sum(np.log(weighted))\n",
    "\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def train_model(X, k, convergence_function, initial_values = None):\n",
    "    \"\"\"\n",
    "    Train the mixture model using the\n",
    "    expectation-maximization algorithm.\n",
    "    E.g., iterate E and M steps from\n",
    "    above until convergence.\n",
    "    If the initial_values are None, initialize them.\n",
    "    Else it's a tuple of the format (MU, SIGMA, PI).\n",
    "    Convergence is reached when convergence_function\n",
    "    returns terminate as True,\n",
    "    see default convergence_function example\n",
    "    in `helper_functions.py`\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    convergence_function = func\n",
    "    initial_values = None or (MU, SIGMA, PI)\n",
    "\n",
    "    returns:\n",
    "    (new_MU, new_SIGMA, new_PI, responsibility)\n",
    "    new_MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    new_SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    new_PI = numpy.ndarray[float] - k\n",
    "    responsibility = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    \"\"\"\n",
    "\n",
    "    MU, SIGMA, PI = initialize_parameters(X, k)\n",
    "    if initial_values is not None:\n",
    "        MU, SIGMA, PI = initial_values\n",
    "\n",
    "    old_likelihood = 0\n",
    "    new_likelihood = loglikelihood(X, PI, MU, SIGMA, k)\n",
    "    count = 0\n",
    "    convrged = False\n",
    "    while not convrged:\n",
    "        responsibility = E_step(X, MU, SIGMA, PI, k)\n",
    "        MU, SIGMA, PI = M_step(X, responsibility, k)\n",
    "        old_likelihood = new_likelihood\n",
    "        new_likelihood = loglikelihood(X, PI, MU, SIGMA, k)\n",
    "        count, convrged = convergence_function(old_likelihood, new_likelihood, count)\n",
    "\n",
    "    return MU, SIGMA, PI, responsibility\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def cluster(r):\n",
    "    \"\"\"\n",
    "    Based on a given responsibilities matrix\n",
    "    return an array of cluster indices.\n",
    "    Assign each datapoint to a cluster based,\n",
    "    on component with a max-likelihood\n",
    "    (maximum responsibility value).\n",
    "\n",
    "    params:\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m - responsibility matrix\n",
    "\n",
    "    return:\n",
    "    clusters = numpy.ndarray[int] - m x 1\n",
    "    \"\"\"\n",
    "    return(np.argmax(r, axis=0))\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def segment(X, MU, k, r):\n",
    "    \"\"\"\n",
    "    Segment the X matrix into k components.\n",
    "    Returns a matrix where each data point is\n",
    "    replaced with its max-likelihood component mean.\n",
    "    E.g., return the original matrix where each pixel's\n",
    "    intensity replaced with its max-likelihood\n",
    "    component mean. (the shape is still mxn, not\n",
    "    original image size)\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    k = int\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m - responsibility matrix\n",
    "\n",
    "    returns:\n",
    "    new_X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    \"\"\"\n",
    "    clusters = cluster(r)\n",
    "    return(MU[clusters])\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def best_segment(X,k,iters):\n",
    "    \"\"\"Determine the best segmentation\n",
    "    of the image by repeatedly\n",
    "    training the model and\n",
    "    calculating its likelihood.\n",
    "    Return the segment with the\n",
    "    highest likelihood.\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    iters = int\n",
    "\n",
    "    returns:\n",
    "    (likelihood, segment)\n",
    "    likelihood = float\n",
    "    segment = numpy.ndarray[numpy.ndarray[float]]\n",
    "    \"\"\"\n",
    "\n",
    "    best_likelihood = 0\n",
    "    best_segment = None\n",
    "\n",
    "    for i in range(iters):\n",
    "        MU, SIGMA, PI, responsibility = train_model(X, k, convergence_function=default_convergence)\n",
    "        print(MU.shape)\n",
    "\n",
    "        likelihood = loglikelihood(X, PI, MU, SIGMA, k)\n",
    "        if likelihood > best_likelihood:\n",
    "            best_likelihood = likelihood\n",
    "            best_segment = segment(X,MU,k, responsibility)\n",
    "\n",
    "    return (best_likelihood, best_segment)\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def bayes_info_criterion(X, PI, MU, SIGMA, k):\n",
    "    \"\"\"\n",
    "    See description above\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k\n",
    "    k = int\n",
    "\n",
    "    return:\n",
    "    bayes_info_criterion = int\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    likelihood = loglikelihood(X, PI, MU, SIGMA, MU.shape[0])\n",
    "    num_params = k * (n + n*(n+1)//2 + 1) - 1\n",
    "    return np.log(m)* num_params -2*likelihood\n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "################ END OF LOCAL TEST CODE SECTION ######################͏︆͏󠄃͏󠄌͏󠄍͏󠄂͏️͏󠄇͏︊͏︃\n",
    "\n",
    "def BIC_likelihood_model_test(image_matrix, comp_means):\n",
    "    \"\"\"Returns the number of components\n",
    "    corresponding to the minimum BIC\n",
    "    and maximum likelihood with respect\n",
    "    to image_matrix and comp_means.\n",
    "\n",
    "    params:\n",
    "    image_matrix = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    comp_means = list(numpy.ndarray[numpy.ndarray[float]]) - list(k x n) (means for each value of k)\n",
    "\n",
    "    returns:\n",
    "    (n_comp_min_bic, n_comp_max_likelihood)\n",
    "    n_comp_min_bic = int\n",
    "    n_comp_max_likelihood = int\n",
    "    \"\"\"\n",
    "    n_bic = 0\n",
    "    n_max_likelihood = 0\n",
    "    min_bic = np.inf\n",
    "    max_likelihood = 0\n",
    "    for k, means in enumerate(comp_means, start=1):\n",
    "        sigma = compute_sigma(image_matrix, means)\n",
    "        pi = np.array([1/k for t in range(1, k+1)])\n",
    "        mu, sigma, pi, r = train_model(X = image_matrix, k=k, convergence_function=default_convergence , initial_values=(means, sigma, pi))\n",
    "        bic = bayes_info_criterion(image_matrix, pi, mu, sigma, k)\n",
    "        #minizizing cost\n",
    "        if bic < min_bic:\n",
    "            min_bic = bic\n",
    "            n_bic = k\n",
    "        #maximizing likelihood\n",
    "        likelihood = loglikelihood(image_matrix, pi, mu, sigma, mu.shape[0])\n",
    "        if likelihood > max_likelihood:\n",
    "            max_likelihood = likelihood\n",
    "            n_max_likelihood = k\n",
    "\n",
    "    return n_bic, n_max_likelihood\n",
    "\n",
    "def return_your_name():\n",
    "    return(\"Kiavosh Peynabard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = image_values.reshape(-1, 3)\n",
    "means = np.array([[0.90980393, 0.8392157, 0.65098041],\n",
    "                      [0.83137256, 0.80784315, 0.69411767],\n",
    "                      [0.67450982, 0.52941179, 0.25490198],\n",
    "                      [0.86666667, 0.8392157, 0.70588237], [0, 0, 0],\n",
    "                      [0.8392157, 0.80392158, 0.63921571]])\n",
    "BIC_likelihood_model_test(X, [means,means,means])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "ai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
